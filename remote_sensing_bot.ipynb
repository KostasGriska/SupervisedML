{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flyff leveling bot\n",
    "\n",
    "This notebooks is my personal test, playing object detection. Using opencv, I will create a simple leveling bot, that would find the nearest target and attack it. The bot is created for Flyff universe, and the imputs would have to be the `png file` of a target (I use target name snipets) and `png file` of character name. In order to swap from 1v1 mode, you will have to change from `doubleClick()` to `.press(\"key\")`\n",
    "## Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import template\n",
    "import cv2 as cv\n",
    "import pyautogui\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import mss\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants ( target and main characted)\n",
    "target_mob = 'banger.PNG'\n",
    "avtr_name = \"avtr_name.PNG\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "### 1. Find all mobs in the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClickPositions(needle_img, haystack_img, threshold=0.5, debug_mode=None):\n",
    "    # https://docs.opencv.org/4.2.0/d4/da8/group__imgcodecs.html\n",
    "    # haystack_img = cv.imread(haystack_img_path, cv.IMREAD_UNCHANGED)\n",
    "    # needle_img = cv.imread(needle_img_path, cv.IMREAD_UNCHANGED)\n",
    "    # Save the dimensions of the needle image\n",
    "    needle_w = needle_img.shape[1]\n",
    "    needle_h = needle_img.shape[0]\n",
    "\n",
    "    # There are 6 methods to choose from:\n",
    "    # TM_CCOEFF, TM_CCOEFF_NORMED, TM_CCORR, TM_CCORR_NORMED, TM_SQDIFF, TM_SQDIFF_NORMED\n",
    "    method = cv.TM_CCOEFF_NORMED\n",
    "    result = cv.matchTemplate(\n",
    "            image = haystack_img,\n",
    "            templ=needle_img,\n",
    "            method = cv.TM_CCOEFF_NORMED\n",
    "        )\n",
    "\n",
    "    # Get the all the positions from the match result that exceed our threshold\n",
    "    locations = np.where(result >= threshold)\n",
    "    locations = list(zip(*locations[::-1]))\n",
    "    #print(locations)\n",
    "\n",
    "    # You'll notice a lot of overlapping rectangles get drawn. We can eliminate those redundant\n",
    "    # locations by using groupRectangles().\n",
    "    # First we need to create the list of [x, y, w, h] rectangles\n",
    "    rectangles = []\n",
    "    for loc in locations:\n",
    "        rect = [int(loc[0]), int(loc[1]), needle_w, needle_h]\n",
    "        # Add every box to the list twice in order to retain single (non-overlapping) boxes\n",
    "        rectangles.append(rect)\n",
    "        rectangles.append(rect)\n",
    "    # Apply group rectangles.\n",
    "    # The groupThreshold parameter should usually be 1. If you put it at 0 then no grouping is\n",
    "    # done. If you put it at 2 then an object needs at least 3 overlapping rectangles to appear\n",
    "    # in the result. I've set eps to 0.5, which is:\n",
    "    # \"Relative difference between sides of the rectangles to merge them into a group.\"\n",
    "    rectangles, weights = cv.groupRectangles(rectangles, groupThreshold=1, eps=0.5)\n",
    "    points = []\n",
    "    if len(rectangles):\n",
    "        line_color = (0, 255, 0)\n",
    "        line_type = cv.LINE_4\n",
    "        marker_color = (255, 0, 255)\n",
    "        marker_type = cv.MARKER_CROSS\n",
    "\n",
    "        # Loop over all the rectangles\n",
    "        for (x, y, w, h) in rectangles:\n",
    "\n",
    "            # Determine the center position\n",
    "            center_x = x + int(w/2)\n",
    "            center_y = y + int(h/2) + 50\n",
    "            # Save the points\n",
    "            points.append((center_x, center_y))\n",
    "\n",
    "            if debug_mode == 'rectangles':\n",
    "                # Determine the box position\n",
    "                top_left = (x, y)\n",
    "                bottom_right = (x + w, y + h)\n",
    "                # Draw the box\n",
    "                cv.rectangle(haystack_img, top_left, bottom_right, color=line_color, \n",
    "                             lineType=line_type, thickness=2)\n",
    "            elif debug_mode == 'points':\n",
    "                # Draw the center point\n",
    "                cv.drawMarker(haystack_img, (center_x, center_y), \n",
    "                              color=marker_color, markerType=marker_type, \n",
    "                              markerSize=40, thickness=2)\n",
    "\n",
    "        if debug_mode:\n",
    "            cv.imshow('Matches', haystack_img)\n",
    "            cv.waitKey(0)\n",
    "            #cv.imwrite('result_click_point.jpg', haystack_img)\n",
    "\n",
    "    return points\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find Avatar position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avatar_position(needle_img, haystack, threshold = 0.5):\n",
    "    # needle_img = cv.imread(avatar, cv.IMREAD_UNCHANGED)\n",
    "    # haystack_img = cv.imread(haystack, cv.IMREAD_UNCHANGED)\n",
    "\n",
    "    needle_w = needle_img.shape[1]\n",
    "    needle_h = needle_img.shape[0]\n",
    "        # # There are 6 methods to choose from:\n",
    "        # # TM_CCOEFF, TM_CCOEFF_NORMED, TM_CCORR, TM_CCORR_NORMED, TM_SQDIFF, TM_SQDIFF_NORMED\n",
    "    result = cv.matchTemplate(haystack, needle_img, cv.TM_CCOEFF_NORMED)\n",
    "    mi_val, ma_val, mi_loc, ma_loc = cv.minMaxLoc(result)\n",
    "    # let's search for the needle and find the center location\n",
    "    if ma_val >= threshold:\n",
    "        top_left = ma_loc\n",
    "        center_x = top_left[0] + int(needle_w/2)\n",
    "        center_y = top_left[1] + int(needle_h/2)\n",
    "        return np.array((center_x, center_y))\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find the closest target relative to the main character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance and return the nearest point to the avatar\n",
    "def distance(p1, p2):\n",
    "    return math.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "\n",
    "def closest(pt, others):\n",
    "    return min(others, key = lambda i: distance(pt, i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Take Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_screenshot():\n",
    "    try:\n",
    "        os.remove('ssf.png')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    os.chdir(temp_dir)\n",
    "    sleep(3)\n",
    "    with mss.mss() as screenshot:\n",
    "        screenshot.shot(output=\"ssf.png\")\n",
    "        hayhay = cv.imread(\"ssf.png\", cv.IMREAD_UNCHANGED) \n",
    "            # cv.imshow('kaaaaaa', hayhay)\n",
    "            # cv.waitKey(0)\n",
    "        return hayhay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. PyAutogui for auto clicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_click(target_mob, avtr_name, geimas):\n",
    "    points = findClickPositions(target_mob, geimas , threshold=0.5)\n",
    "    avatar_center = find_avatar_position(avtr_name, geimas, threshold = 0.5)\n",
    "    click_pos = closest(avatar_center, points)\n",
    "    return pyautogui.doubleClick(click_pos[0], click_pos[1])\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize the main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3): ### checkup look ( test if it works)\n",
    "    sleep(3)\n",
    "    with mss.mss() as screenshot:\n",
    "        hayhay = np.array(screenshot.grab(screenshot.monitors[0]))\n",
    "\n",
    "    target_mob = cv.imread(target_mob, cv.IMREAD_UNCHANGED)\n",
    "    avtr_name = cv.imread(avtr_name, cv.IMREAD_UNCHANGED)\n",
    "\n",
    "    points = findClickPositions(target_mob, hayhay , threshold=0.7)\n",
    "    avatar_center = find_avatar_position(avtr_name, hayhay, threshold = 0.7)\n",
    "    try:\n",
    "        click_pos = closest(avatar_center, points)\n",
    "        pyautogui.doubleClick(click_pos[0], click_pos[1])\n",
    "        key = cv.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future development (continous leveling)\n",
    "# for multiple checks like this\n",
    "            # checks = {\n",
    "            #         \"recieve.png\": 'recieve',\n",
    "            #         \"next.png\": 'next',...}\n",
    "\n",
    "# need what is being searched for and haystackImage is where we are looking\n",
    "\n",
    "# def detect(imgDir, haystackImage, confidence=0.85, cache=False):\n",
    "#     if (pyautogui.locate(os.path.join('images', imgDir), haystackImage, confidence=confidence)) is not None:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# from matplotlib import image\n",
    "# hsImage = image.imread('images\\\\capture.jpeg')\n",
    "# hsImage = hsImage[:,:,::-1] # convert RGB to BGR\n",
    "# detect('needleImg.png', hsImage, cache=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
